---
title: å´æ©è¾¾ã€Šæœºå™¨å­¦ä¹ ã€‹ç¬”è®°ï¼ˆäºŒï¼‰â€”â€”å•å˜é‡çº¿æ€§å›å½’
comments: true
mathjax: true
toc: true
tocnumber: false
music: false
image: false
tags:
  - Machine Learning
categories:
  - ç¬”è®°æ•´ç†
  - æœºå™¨å­¦ä¹ 
abbrlink: df3b9948
date: 2019-07-16 11:49:49
description: 'æœ¬æ–‡å†…å®¹ä¸»è¦ä»‹ç»ã€Œå•å˜é‡çº¿æ€§å›å½’ã€çš„é—®é¢˜ã€‚å€ŸåŠ©ä¸€ä¸ªå•å˜é‡çº¿æ€§å›å½’æ¨¡å‹ï¼Œæ±‚å¾—å®ƒçš„ã€Œä»£ä»·å‡½æ•°ã€ï¼Œå¹¶åˆ©ç”¨ã€Œæ¢¯åº¦ä¸‹é™ã€çš„æ–¹æ³•æ¥æœ€å°åŒ–ä»£ä»·å‡½æ•°ã€‚'
---

> æœ¬æ–‡å†…å®¹ä¸»è¦ä»‹ç»ã€Œå•å˜é‡çº¿æ€§å›å½’ã€çš„é—®é¢˜ã€‚
>
> å€ŸåŠ©ä¸€ä¸ªå•å˜é‡çº¿æ€§å›å½’æ¨¡å‹ï¼Œæ±‚å¾—å®ƒçš„ã€Œä»£ä»·å‡½æ•°ã€ï¼Œå¹¶åˆ©ç”¨ã€Œæ¢¯åº¦ä¸‹é™ã€çš„æ–¹æ³•æ¥æœ€å°åŒ–ä»£ä»·å‡½æ•°ã€‚



## Linear Regression with One Variable

### 2.1 Univariate linear regression

* $ğ‘š$ ä»£è¡¨è®­ç»ƒé›†ä¸­å®ä¾‹çš„æ•°é‡ 
* $ğ‘¥$ ä»£è¡¨ç‰¹å¾/è¾“å…¥å˜é‡ 
* $ğ‘¦â€‹$ ä»£è¡¨ç›®æ ‡å˜é‡/è¾“å‡ºå˜é‡ 
* $(ğ‘¥,ğ‘¦)â€‹$ ä»£è¡¨è®­ç»ƒé›†ä¸­çš„å®ä¾‹ 
* $(ğ‘¥^{(ğ‘–)},ğ‘¦^{(ğ‘–)})$ ä»£è¡¨ç¬¬ğ‘– ä¸ªè§‚å¯Ÿå®ä¾‹ 
* $â„$ ä»£è¡¨å­¦ä¹ ç®—æ³•çš„è§£å†³æ–¹æ¡ˆæˆ–å‡½æ•°ä¹Ÿç§°ä¸ºå‡è®¾ï¼ˆ**hypothesis**ï¼‰ 

è¿™é‡Œä»¥æˆ¿å±‹ä»·æ ¼é¢„æµ‹ä¸ºä¾‹ï¼Œæˆ‘ä»¬çš„å­¦ä¹ ç®—æ³•ä¸­ï¼Œæˆ‘ä¹ˆéœ€è¦é€šè¿‡å­¦ä¹ å¾—åˆ°ä¸€ä¸ªå‡è®¾ hï¼Œh è¡¨ç¤ºä¸€ä¸ªå‡½æ•°ï¼Œè¾“å…¥æˆ¿å±‹å°ºå¯¸å¤§å° xï¼Œä»è€Œå¾—åˆ°è¾“å‡ºæˆ¿å±‹çš„ä»·æ ¼ yï¼Œå› æ­¤ h æ˜¯ä¸€ä¸ªä» x åˆ° y çš„å‡½æ•°æ˜ å°„ã€‚
![](https://photo.hushhw.cn/20190716121509.png)

è¿™é‡Œæˆ‘ä»¬é‡‡ç”¨ $h_{\theta}(x) = \theta_0 + \theta_1x$ æ¥è¡¨è¾¾ hï¼Œå› ä¸ºåªå«æœ‰ä¸€ä¸ªç‰¹å¾/è¾“å…¥å˜é‡ï¼Œå› æ­¤è¢«ç§°ä¸º**å•å˜é‡çº¿æ€§å›å½’é—®é¢˜ï¼ˆUnivariate linear regressionï¼‰**ã€‚

â€‹           

### 2.2 Cost function

æˆ‘ä»¬å‰é¢å¾—åˆ°äº†é¢„æµ‹çš„å‡½æ•°æ˜¯ä¸€ä¸ªçº¿æ€§å‡½æ•°ï¼š$h_{\theta}(x) = \theta_0 + \theta_1x$ï¼Œä¸‹é¢æˆ‘ä»¬éœ€è¦é€‰æ‹©åˆé€‚çš„å‚æ•°ï¼ˆparametersï¼‰$\theta_0$ å’Œ $\theta_1$ æ¥ä½¿å¾—æˆ‘ä»¬çš„é¢„æµ‹æ›´åŠ å‡†ç¡®ï¼Œæ¨¡å‹æ‰€é¢„æµ‹çš„å€¼å’Œè®­ç»ƒé›†ä¸­å®é™…å€¼ä¹‹é—´çš„å·®è·å°±æ˜¯**å»ºæ¨¡è¯¯å·®ï¼ˆmodeling errorï¼‰**ã€‚

ä¸€èˆ¬è€Œè¨€ï¼Œæˆ‘ä»¬é€šè¿‡è°ƒæ•´ Î¸ï¼Œä½¿å¾—æ‰€æœ‰è®­ç»ƒé›†æ•°æ®ä¸å…¶æ‹Ÿåˆæ•°æ®çš„å·®çš„å¹³æ–¹å’Œæ›´å°ï¼Œå³è®¤ä¸ºå¾—åˆ°äº†æ‹Ÿåˆåº¦æ›´å¥½çš„å‡½æ•°ã€‚ä»è€Œæˆ‘ä»¬å¾—åˆ°**ä»£ä»·å‡½æ•°ï¼ˆcost functionï¼‰**ï¼š
$$
Jï¼ˆ\theta_0,\theta_1) = \frac{1}{2m}\sum^m_{i=1}(h_{\theta}(x^{(i)})-y^{(i)})^2
$$
è¿™é‡Œçš„$\frac{1}{2}$ æ˜¯ä¸ºäº†æ–¹ä¾¿åé¢çš„è¿ç®—è€ŒåŠ ä¸Šçš„ã€‚

ä»£ä»·å‡½æ•°åˆè¢«ç§°ä¸º**å¹³æ–¹è¯¯å·®å‡½æ•°**ï¼Œæœ‰æ—¶ä¹Ÿè¢«ç§°ä¸º**å¹³æ–¹è¯¯å·®ä»£ä»·å‡½æ•°**ã€‚æ±‚è¯¯å·®çš„å¹³æ–¹åœ¨å¤§å¤šæ•°é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯å›å½’é—®é¢˜éƒ½æ˜¯ä¸€ä¸ªåˆç†çš„é€‰æ‹©ã€‚

å›é¡¾ä¸€ä¸‹ç›®å‰ä¸ºæ­¢æˆ‘ä»¬çš„æ€è·¯ï¼š

![](https://photo.hushhw.cn/20190716133921.png)

â€‹          

### 2.3 Gradient Descent

æœ¬èŠ‚æ¥è§£å†³å¦‚ä½•æ±‚ $minimize J(\theta_0, \theta_1)$ çš„é—®é¢˜ã€‚

**æ¢¯åº¦ä¸‹é™ï¼ˆGradient Descent)** æ˜¯ä¸€ä¸ªç”¨æ¥æ±‚å‡½æ•°æœ€å°å€¼çš„ç®—æ³•ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨æ¢¯åº¦ä¸‹é™ç®—æ³•æ±‚å‡ºä»£ä»·å‡½æ•°æœ€å°å€¼ã€‚

æ¢¯åº¦ä¸‹é™èƒŒåçš„æ€æƒ³æ˜¯ï¼šå¼€å§‹æ—¶æˆ‘ä»¬éšæœºé€‰æ‹©ä¸€ä¸ªå‚æ•°çš„ç»„åˆ $(ğœƒ_0,ğœƒ_1,...,ğœƒ_ğ‘›)$ï¼Œè®¡ç®—ä»£ä»·å‡½æ•°ï¼Œç„¶åæˆ‘ä»¬å¯»æ‰¾ä¸‹ä¸€ä¸ªèƒ½è®©ä»£ä»·å‡½æ•°å€¼ä¸‹é™æœ€å¤šçš„å‚æ•°ç»„åˆã€‚æˆ‘ä»¬æŒç»­è¿™ä¹ˆåšç›´åˆ°åˆ°åˆ°ä¸€ä¸ªå±€éƒ¨æœ€å°å€¼ï¼ˆlocal minimumï¼‰ï¼Œå› ä¸ºæˆ‘ä»¬å¹¶æ²¡æœ‰å°è¯•å®Œæ‰€æœ‰çš„å‚æ•°ç»„åˆï¼Œæ‰€ä»¥ä¸èƒ½ç¡®å®šæˆ‘ä»¬å¾—åˆ°çš„å±€éƒ¨æœ€å°å€¼æ˜¯å¦ä¾¿æ˜¯å…¨å±€æœ€å°å€¼ï¼ˆglobal minimumï¼‰ï¼Œé€‰æ‹©ä¸åŒçš„åˆå§‹å‚æ•°ç»„åˆï¼Œå¯èƒ½ä¼šæ‰¾åˆ°ä¸åŒçš„å±€éƒ¨æœ€å°å€¼ã€‚ 

![](https://photo.hushhw.cn/20190716135043.png)

![](https://photo.hushhw.cn/20190716135116.png)

ä¸Šé¢æ˜¯ä¸€ä¸ªéçº¿æ€§å‡½æ•°çš„ä»£ä»·å‡½æ•°ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œé€‰å–ä¸åŒçš„åˆå§‹å€¼ Î¸ï¼Œå¯èƒ½ä¼šä½¿å¾—è¿­ä»£çš„ä»£ä»·å‡½æ•°æœ€åè¿›å…¥ä¸åŒçš„æå°å€¼ç‚¹ã€‚

æ¢¯åº¦ä¸‹é™ç®—æ³•å…¬å¼ï¼š

![](https://photo.hushhw.cn/20190716135452.png)

å…¶ä¸­ï¼Œ

* $\alpha$ æ˜¯**å­¦ä¹ ç‡ï¼ˆlearning rateï¼‰**ï¼Œå®ƒå†³å®šäº†æˆ‘ä»¬æ²¿ç€èƒ½è®©ä»£ä»·å‡½æ•°ä¸‹é™ç¨‹åº¦æœ€å¤§çš„æ–¹å‘å‘ä¸‹è¿ˆå‡ºçš„æ­¥å­æœ‰å¤šå¤§ã€‚$\alphaâ€‹$ ä¸èƒ½å¤ªå¤§ä¹Ÿä¸èƒ½å¤ªå°ï¼Œå¤ªå°äº†ä¼šä½¿å¾—ç§»åŠ¨çš„é€Ÿç‡å¾ˆæ…¢ï¼Œéœ€è¦å¾ˆå¤šæ­¥æ‰èƒ½åˆ°è¾¾å…¨å±€æœ€ä½ç‚¹ã€‚å¤ªå¤§äº†å¯èƒ½ä¼šç›´æ¥è¶Šè¿‡äº†æœ€ä½ç‚¹ï¼Œç”šè‡³å¯èƒ½æ— æ³•æ”¶æ•›ï¼Œç”šè‡³å‘æ•£ã€‚
* := è¡¨ç¤ºèµ‹å€¼ï¼ˆassignmentï¼‰

å¯¹äºå•å˜é‡çº¿æ€§å›å½’çš„æ¢¯åº¦å‡½æ•°è€Œè¨€ï¼Œå…¶ä»£ä»·å‡½æ•° J å…³äºå‚æ•° Î¸çš„å›¾åƒå¦‚ä¸‹ï¼Œåªæœ‰ä¸€ä¸ªæå€¼ä»¥åŠæœ€å€¼ï¼š

![](https://photo.hushhw.cn/20190716141637.png)

æˆ‘ä»¬è®©æ¨¡å‹å†ç®€åŒ–ä¸€ä¸‹ï¼Œå–J(Î¸)=Î¸x,å…¶ä»£ä»·å‡½æ•°å…³äºÎ¸çš„å›¾åƒå¦‚ä¸‹ã€‚æˆ‘ä»¬é€šè¿‡è§‚å¯Ÿä»–çš„è¿­ä»£è¿‡ç¨‹ï¼Œæœ‰åŠ©äºç†è§£æ¢¯åº¦ä¸‹é™ç®—æ³•ï¼š

![](https://photo.hushhw.cn/20190716141721.png)

å¯ä»¥çœ‹åˆ°ï¼š

* å½“ Î¸ å¤§äºæœ€å°å€¼æ—¶ï¼Œå¯¼æ•°ä¸ºæ­£ï¼Œé‚£ä¹ˆè¿­ä»£å…¬å¼ $\theta := \theta - \alpha\frac{âˆ‚}{âˆ‚{\theta}}J(\theta)â€‹$ é‡Œï¼ŒÎ¸ å‡å»ä¸€ä¸ªæ­£æ•°ï¼Œå‘å·¦å¾€æœ€å°å€¼é€¼è¿‘ï¼›
* å½“Î¸å°äºæœ€å°å€¼æ—¶ï¼Œå¯¼æ•°ä¸ºè´Ÿï¼Œé‚£ä¹ˆè¿­ä»£å…¬å¼ $\theta := \theta - \alpha\frac{âˆ‚}{âˆ‚{\theta}}J(\theta)$ é‡Œï¼ŒÎ¸ å‡å»ä¸€ä¸ªè´Ÿæ•°ï¼Œå‘å³å¾€æœ€å°å€¼é€¼è¿‘ã€‚

â€‹          

### 2.4 Gradient Descent For Linear Regression

æ¢¯åº¦ä¸‹é™ï¼ˆGradient Descentï¼‰æ˜¯å¾ˆå¸¸ç”¨çš„ç®—æ³•ï¼Œè¿™ä¸€èŠ‚æˆ‘ä»¬å°†ç”¨åˆ°æ­¤ç®—æ³•ï¼Œå¹¶å°†å…¶åº”ç”¨äºå…·ä½“çš„æ‹Ÿåˆç›´çº¿çš„çº¿æ€§å›å½’ç®—æ³•é‡Œã€‚ 

![](https://photo.hushhw.cn/20190716165528.png)

â€‹          

## ä¸“ä¸šåè¯æ•´ç†

* `hypothesis`ï¼šå‡è®¾
* `parameters`ï¼šå‚æ•°
* `Gradient Descent`ï¼šæ¢¯åº¦ä¸‹é™
* `Univariate linear regression`ï¼šå•å˜é‡çº¿æ€§å›å½’
* `cost function`ï¼šä»£ä»·å‡½æ•°
* `learning rate`ï¼šå­¦ä¹ ç‡

* `derivative term`ï¼šå¯¼æ•°é¡¹ã€`partial derivative`ï¼šåå¯¼æ•°
* `equation`ï¼šæ–¹ç¨‹å¼
* `positive slope`ï¼šæ­£æ–œç‡ã€`negative slope`ï¼šè´Ÿæ–œç‡





## å‚è€ƒ

> [é©¿èˆŸå°ç«™](https://www.zhouyongyi.com/andrew-ng-machine-learning-notes-2/)
>
> [Coursera-ML-AndrewNg-Notes](https://github.com/fengdu78/Coursera-ML-AndrewNg-Notes)
>
> [æ–¯å¦ç¦å¤§å­¦ 2014 æœºå™¨å­¦ä¹ ](https://www.coursera.org/course/ml )

