<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="hushhw × Wiki"><meta name="google-site-verification"><meta name="baidu-site-verification"><title>机器学习中评估分类器性能 | hushhw × Wiki</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.3.1/jquery.min.js"></script><link rel="icon" mask sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');ga('create','UA-132675789-2','auto');ga('send','pageview');
</script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = 'https://hm.baidu.com/hm.js?' + '972cc0516975a00c2c5900eb5e98039d';
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();

</script><script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script><link href="//cdn.bootcss.com/pace/1.0.2/themes/blue/pace-theme-flash.css" rel="stylesheet"><script>(function(){ var bp = document.createElement('script'); var curProtocol = window.location.protocol.split(':')[0];if (curProtocol === 'https') {bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';} else {bp.src = 'http://push.zhanzhang.baidu.com/push.js';}var s = document.getElementsByTagName("script")[0];s.parentNode.insertBefore(bp, s);})();</script></head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-132675789-2"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());

gtag('config', 'UA-132675789-2');
</script><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">机器学习中评估分类器性能</h1><a id="logo" href="/.">hushhw × Wiki</a><p class="description"></p></div><div id="nav-menu"><a href="/tech/"><i class="fa fa-battery-full"> 技术</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/tags/"><i class="fa fa-tag"> 标签</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"> <h1 class="post-title">机器学习中评估分类器性能</h1><div class="post-meta">2019-10-21<script src="https://photo.hushhw.cn/busuanzi.pure.mini.js" async></script><span class="busuanzi_container_page_pv"> • <span id="busuanzi_value_page_pv"></span><span> 阅读</span></span><span class="post-time"><span class="post-meta-item-text"> • </span><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i><span class="post-count"> 2,106</span><span class="post-meta-item-text"> 字</span></span></span><span class="post-time"> • <span class="post-meta-item-icon"><i class="fa fa-hourglass-half"></i><span class="post-count"> 9</span><span class="post-meta-item-text"> 分钟</span></span></span></div><a class="disqus-comment-count" href="/posts/f2b20d45.html#vcomment"><span class="valine-comment-count" data-xid="/posts/f2b20d45.html"></span><span> 条评论</span></a><div class="post-content"><h2 id="混淆矩阵（Confusion-Matrix）"><a href="#混淆矩阵（Confusion-Matrix）" class="headerlink" title="混淆矩阵（Confusion Matrix）"></a>混淆矩阵（Confusion Matrix）</h2><p>在机器学习领域和统计分类问题中，<strong>混淆矩阵</strong>（<strong>confusion matrix</strong>）是可视化工具，特别用于监督学习，在无监督学习一般叫做匹配矩阵。矩阵的每一列代表一个类的实例预测，而每一行表示一个实际的类的实例。之所以如此命名，是因为通过这个矩阵可以方便地看出机器是否将两个不同的类混淆了（比如说把一个类错当成了另一个）。<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup></p>
<p>对于二分类问题，混淆矩阵为一个 2*2 的表，行代表真实值，列代表预测值，见下表：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">真实 \ 预测</th>
<th style="text-align:center">0</th>
<th style="text-align:center">1</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><strong>0</strong></td>
<td style="text-align:center">预测 negative 正确（<strong>TN</strong>）</td>
<td style="text-align:center">预测 positive 错误（<strong>FP</strong>）</td>
</tr>
<tr>
<td style="text-align:center"><strong>1</strong></td>
<td style="text-align:center">预测 negative 错误（<strong>FN</strong>）</td>
<td style="text-align:center">预测 positive 正确（<strong>TP</strong>）</td>
</tr>
</tbody>
</table>
</div>
<p>以「患癌症问题」举例，上表中 <code>0</code> 代表未得癌症，<code>1</code> 代表得了癌症，行代表患癌症的真实值，列代表患癌症的预测值，那么，<code>TN</code> 就代表着真实情况没有得癌症且预测没有得癌症正确，同样 <code>FN</code> 代表真实情况得了癌症但预测其未得癌症。</p>
<p>​          </p>
<h2 id="精准率和召回率"><a href="#精准率和召回率" class="headerlink" title="精准率和召回率"></a>精准率和召回率</h2><p><strong>精准率（precision）</strong>：在所有预测值为 <code>1</code> 的情况下，实际也正确的概率。例如在癌症问题中表示预测患癌症成功的概率。公式如下：</p>
<script type="math/tex; mode=display">
precision = \frac{TP}{TP+FP}</script><p><strong>召回率（recall）</strong>：在所有真实值为 <code>1</code> 的情况下，预测正确的概率。例如在癌症问题中表示患癌症的人群中成功预测的概率。公式如下：</p>
<script type="math/tex; mode=display">
recall = \frac{TP}{TP+FN}</script><p>下面代码实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"></span><br><span class="line"><span class="comment"># 引入手写识别数据集</span></span><br><span class="line">digits = datasets.load_digits()</span><br><span class="line">X = digits.data</span><br><span class="line">y = digits.target.copy()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 为了让数据集变成二分类问题，做如下处理</span></span><br><span class="line">y[digits.target == <span class="number">9</span>] = <span class="number">1</span></span><br><span class="line">y[digits.target != <span class="number">9</span>] = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line">log_reg = LogisticRegression()</span><br><span class="line">log_reg.fit(X_train, y_train)</span><br><span class="line">log_reg.score(X_test, y_test)</span><br><span class="line"><span class="comment"># 0.97555555555555551</span></span><br><span class="line"></span><br><span class="line">y_log_predict = log_reg.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># TN</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">TN</span><span class="params">(y_true, y_predict)</span>:</span></span><br><span class="line">    <span class="keyword">assert</span> len(y_true) == len(y_predict)</span><br><span class="line">    <span class="keyword">return</span> np.sum((y_true == <span class="number">0</span>) &amp; (y_predict == <span class="number">0</span>))</span><br><span class="line">TN(y_test, y_log_predict)</span><br><span class="line"><span class="comment"># 397</span></span><br><span class="line"><span class="comment"># FP</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">FP</span><span class="params">(y_true, y_predict)</span>:</span></span><br><span class="line">    <span class="keyword">assert</span> len(y_true) == len(y_predict)</span><br><span class="line">    <span class="keyword">return</span> np.sum((y_true == <span class="number">0</span>) &amp; (y_predict == <span class="number">1</span>))</span><br><span class="line">FP(y_test, y_log_predict)</span><br><span class="line"><span class="comment"># 5</span></span><br><span class="line"><span class="comment"># FN</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">FN</span><span class="params">(y_true, y_predict)</span>:</span></span><br><span class="line">    <span class="keyword">assert</span> len(y_true) == len(y_predict)</span><br><span class="line">    <span class="keyword">return</span> np.sum((y_true == <span class="number">1</span>) &amp; (y_predict == <span class="number">0</span>))</span><br><span class="line">FN(y_test, y_log_predict)</span><br><span class="line"><span class="comment"># 6</span></span><br><span class="line"><span class="comment"># TP</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">TP</span><span class="params">(y_true, y_predict)</span>:</span></span><br><span class="line">    <span class="keyword">assert</span> len(y_true) == len(y_predict)</span><br><span class="line">    <span class="keyword">return</span> np.sum((y_true == <span class="number">1</span>) &amp; (y_predict == <span class="number">1</span>))</span><br><span class="line">TP(y_test, y_log_predict)</span><br><span class="line"><span class="comment">#42</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 混淆矩阵</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">confusion_matrix</span><span class="params">(y_true, y_predict)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> np.array([</span><br><span class="line">        [TN(y_true, y_predict), FP(y_true, y_predict)],</span><br><span class="line">        [FN(y_true, y_predict), TP(y_true, y_predict)]</span><br><span class="line">    ])</span><br><span class="line">confusion_matrix(y_test, y_log_predict)</span><br><span class="line"><span class="comment">#array([[397,   5],</span></span><br><span class="line"><span class="comment">#       [  6,  42]])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 精准率</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">precision_score</span><span class="params">(y_true, y_predict)</span>:</span></span><br><span class="line">    tp = TP(y_true, y_predict)</span><br><span class="line">    fp = FP(y_true, y_predict)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">return</span> tp / (tp + fp)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0.0</span>   </span><br><span class="line">precision_score(y_test, y_log_predict)</span><br><span class="line"><span class="comment"># 0.8936170212765957</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 召回率</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">recall_score</span><span class="params">(y_true, y_predict)</span>:</span></span><br><span class="line">    tp = TP(y_true, y_predict)</span><br><span class="line">    fn = FN(y_true, y_predict)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">return</span> tp / (tp + fn)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0.0</span></span><br><span class="line">recall_score(y_test, y_log_predict)</span><br><span class="line"><span class="comment"># 0.875</span></span><br></pre></td></tr></table></figure>
<p>在 <code>Scikit-learn</code> 中实现混淆矩阵、精准率和召回率</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line">confusion_matrix(y_test, y_log_predict)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> precision_score</span><br><span class="line">precision_score(y_test, y_log_predict)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> recall_score</span><br><span class="line">recall_score(y_test, y_log_predict)</span><br></pre></td></tr></table></figure>
<p>​          </p>
<h2 id="F1-Score"><a href="#F1-Score" class="headerlink" title="F1 Score"></a>F1 Score</h2><p>对于精准率和召回率，在不同的场景有不同的侧重点。</p>
<p>在股票预测问题中，设股票增长为 <code>1</code>，我们更加关注精准率，即我们预测股票增长情况下预测正确的概率，而对于回归率我们并不太关心，因为召回率代表着实际会增长的股票我们预测到会增长的股票的概率，而增长的股票有很多，我们只是漏掉了部分会增长的股票而已，我们并没有什么损失；在病人诊断问题中，我们就更加关注召回率，即病人已经得病了能够诊断出其患病的概率，显然这时候召回率越高越好，能够不漏掉任何一个患病的病人，而精准率低一些并没有关系，即有一些人没有病被预测为有病，再继续做检查确诊就行了，不会造成巨大危害。</p>
<p>如果要同时关注这两个指标，就需要引入一个新的指标——<strong>F1 Score</strong></p>
<p>F1 Score 是精准率和召回率的调和平均值</p>
<script type="math/tex; mode=display">
F_1 = \frac2{\frac1{precision}+\frac1{recall}} = \frac{2\times precision\times recall}{precision + recall}</script><p>下面尝试不同的精准率和召回率下，F1 Score 的值变化</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f1_score</span><span class="params">(precision, recall)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">2</span> * precision * recall / (precision + recall)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">precision = <span class="number">0.5</span></span><br><span class="line">recall = <span class="number">0.5</span></span><br><span class="line">f1_score(precision, recall)</span><br><span class="line"><span class="comment"># 0.5</span></span><br><span class="line"></span><br><span class="line">precision = <span class="number">0.1</span></span><br><span class="line">recall = <span class="number">0.9</span></span><br><span class="line">f1_score(precision, recall)</span><br><span class="line"><span class="comment"># 0.18000000000000002</span></span><br><span class="line"></span><br><span class="line">precision = <span class="number">0.0</span></span><br><span class="line">recall = <span class="number">1.0</span></span><br><span class="line">f1_score(precision, recall)</span><br><span class="line"><span class="comment"># 0.0</span></span><br></pre></td></tr></table></figure>
<p>在前面的例子中我们测得了精准率和召回率，现在使用 <code>Scikit-learn</code> 计算 f1_score：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line">confusion_matrix(y_test, y_log_predict)</span><br><span class="line"><span class="comment">#array([[403,   2],</span></span><br><span class="line"><span class="comment">#       [  9,  36]])</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> precision_score</span><br><span class="line">precision_score(y_test, y_log_predict)</span><br><span class="line"><span class="comment"># 0.94736842105263153</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> recall_score</span><br><span class="line">recall_score(y_test, y_log_predict)</span><br><span class="line"><span class="comment"># 0.80000000000000004</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> f1_score</span><br><span class="line">f1_score(y_test, y_log_predict)</span><br><span class="line"><span class="comment"># 0.8842105263157894</span></span><br></pre></td></tr></table></figure>
<p>F1 Score 对那些具有相近的精准率和召回率的分类器更为有利。</p>
<p>​            </p>
<h2 id="Precision-recall-的平衡"><a href="#Precision-recall-的平衡" class="headerlink" title="Precision-recall 的平衡"></a>Precision-recall 的平衡</h2><p>下图中用竖线代表阈值，划分左右两边分别为预测为 0 和 1，五角星代表实际值为 1，圆代表 0。</p>
<p><img src="https://photo.hushhw.cn/20191021200918.png" alt></p>
<p>当阈值为 0 ，小于 0，大于 0 时分别不同的精准率和召回率，由此可知鱼与熊掌不可兼得。</p>
<p><code>Scikit-learn</code> 不允许直接设置阈值，但可以访问它用于预测的决策分数。不是调用分类器的 predict() 方法，而是调用 decision_function() 方法，这个方法返回每个实例的分数，然后就可以根据这些分数，使用任意阈值进行预测了：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">decision_scores = log_reg.decision_function(X_test)</span><br><span class="line"></span><br><span class="line">np.min(decision_scores)</span><br><span class="line"><span class="comment"># -61.02813630853092</span></span><br><span class="line">np.max(decision_scores)</span><br><span class="line"><span class="comment"># 17.504275181503946</span></span><br><span class="line"></span><br><span class="line">y_predict_2 = np.array(decision_scores &gt;= <span class="number">5</span>, dtype=<span class="string">'int'</span>)</span><br><span class="line">confusion_matrix(y_test, y_predict_2)</span><br><span class="line"><span class="comment">#array([[402,   0],</span></span><br><span class="line"><span class="comment">#       [ 20,  28]], dtype=int64)</span></span><br><span class="line">precision_score(y_test, y_predict_2)</span><br><span class="line"><span class="comment"># 1.0</span></span><br><span class="line">recall_score(y_test, y_predict_2)</span><br><span class="line"><span class="comment"># 0.5833333333333334</span></span><br><span class="line"></span><br><span class="line">y_predict_3 = np.array(decision_scores &gt;= <span class="number">-5</span>, dtype=<span class="string">'int'</span>)</span><br><span class="line">confusion_matrix(y_test, y_predict_3)</span><br><span class="line"><span class="comment">#array([[379,  23],</span></span><br><span class="line"><span class="comment">#       [  2,  46]], dtype=int64)</span></span><br><span class="line">precision_score(y_test, y_predict_3)</span><br><span class="line"><span class="comment"># 0.6666666666666666</span></span><br><span class="line">recall_score(y_test, y_predict_3)</span><br><span class="line"><span class="comment"># 0.9583333333333334</span></span><br></pre></td></tr></table></figure>
<p>下面用 for 循环拿到所有的阈值，绘制成图：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">precisions = []</span><br><span class="line">recalls = []</span><br><span class="line">thresholds = np.arange(np.min(decision_scores), np.max(decision_scores), <span class="number">0.1</span>)</span><br><span class="line"><span class="keyword">for</span> threshold <span class="keyword">in</span> thresholds:</span><br><span class="line">    y_predict = np.array(decision_scores &gt;= threshold, dtype = <span class="string">'int'</span>)</span><br><span class="line">    precisions.append(precision_score(y_test, y_predict))</span><br><span class="line">    recalls.append(recall_score(y_test, y_predict))</span><br><span class="line">    </span><br><span class="line">plt.plot(thresholds, precisions)</span><br><span class="line">plt.plot(thresholds, recalls)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://photo.hushhw.cn/20191021205050.png" alt></p>
<p>​         </p>
<h2 id="Precision-Recall-曲线"><a href="#Precision-Recall-曲线" class="headerlink" title="Precision-Recall 曲线"></a>Precision-Recall 曲线</h2><p>将 Precision 和 Recall 分别放在坐标轴的 x 和 y 轴上，可以清晰的观察到两者的关系：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(precisions, recalls)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://photo.hushhw.cn/20191021205339.png" alt></p>
<p>在 <code>Scikit-learn</code> 中可以直接调用 <code>precision_recall_curve</code> 方法来得到相应参数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> precision_recall_curve</span><br><span class="line">precisions, recalls, thresholds = precision_recall_curve(y_test, decision_scores)</span><br></pre></td></tr></table></figure>
<p>返回了三个参数，分别是 precisions、recalls 和 thresholds（阈值），下面看看这几个参数的元素个数：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">precisions.shape</span><br><span class="line"><span class="comment"># (93,)</span></span><br><span class="line">recalls.shape</span><br><span class="line"><span class="comment"># (93,)</span></span><br><span class="line">thresholds.shape</span><br><span class="line"><span class="comment"># (92,)</span></span><br></pre></td></tr></table></figure></p>
<p>翻阅官方文档<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup>可以知道最后一个精准率或回归率的值默认为 1 或 0，且没有 threshold。</p>
<p>最后用 <code>matplotlib</code> 绘制即可：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(thresholds, precisons[:<span class="number">-1</span>])</span><br><span class="line">plt.plot(thresholds, recalls[:<span class="number">-1</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://photo.hushhw.cn/20191021210859.png" alt></p>
<p>若绘制前面那种 precison 与 recall 的坐标系：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(precisions, recalls)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://photo.hushhw.cn/20191021211010.png" alt></p>
<p>对比前面的图会发现这里只是前面的中间部分，是因为 precision_recall_curve 选择了它认为最重要的数据。</p>
<p>​           </p>
<h2 id="ROC-曲线"><a href="#ROC-曲线" class="headerlink" title="ROC 曲线"></a>ROC 曲线</h2><p>ROC 曲线经常与二元分类器一起使用，它与 precison-recall 曲线非常相似，但绘制的不是精准率和召回率，而是真正类率（<strong>TPR</strong>）与假正类率（<strong>FPR</strong>）。</p>
<p>回到前面的混淆矩阵二分类问题上，其实 TPR = recall，二者是一样的含义，而 FPR 表示在真实值为 0 的情况下，预测 为 1 的概率，公式：</p>
<script type="math/tex; mode=display">
FPR = \frac{FP}{TN+FP}</script><p>TPR 和 FPR 二者的关系如下图，同大同小：</p>
<p><img src="https://photo.hushhw.cn/20191021213307.png" alt></p>
<p>使用 <code>Scikit-learn</code> 中的 <code>roc_curve</code> 方法可以得到想要的参数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_curve</span><br><span class="line">fprs, tprs, thresholds = roc_curve(y_test, decision_scores)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(fprs, tprs)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>绘制结果：</p>
<p><img src="https://photo.hushhw.cn/20191021213534.png" alt></p>
<p>ROC 曲线一般用来比较两个模型孰优孰劣，其<strong>曲线下面积（AUC）</strong>是非常重要的参数，完美的 ROC AUC 等于 1，而纯随机分类器的 ROC AUC 等于 0.5。</p>
<p>下面是 <code>Scikit-learn</code> 中提供的方法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score</span><br><span class="line">roc_auc_score(y_test, decision_scores)</span><br><span class="line"><span class="comment"># 0.98304526748971188</span></span><br></pre></td></tr></table></figure>
<p>​             </p>
<p>完整代码：<a href="https://github.com/hushhw/Machine_Learning_Algorithms_Note/blob/master/Classification-Performance-Measures.ipynb" target="_blank" rel="noopener"><strong>Classification-Performance-Measures.ipynb</strong></a></p>
<div id="footnotes"><hr><div id="footnotelist"><ol style="list-style:none; padding-left: 0;"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">1.</span><span style="display: inline-block; vertical-align: top;"><a href="https://zh.wikipedia.org/wiki/%E6%B7%B7%E6%B7%86%E7%9F%A9%E9%98%B5" target="_blank" rel="noopener">维基百科</a></span><a href="#fnref:1" rev="footnote"> ↩</a></li><li id="fn:2"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">2.</span><span style="display: inline-block; vertical-align: top;"><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html#sklearn.metrics.precision_recall_curve" target="_blank" rel="noopener">precision_recall_curve</a></span><a href="#fnref:2" rev="footnote"> ↩</a></li></ol></div></div></div><div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者：</strong>hushhw</li><li class="post-copyright-link"><strong>本文链接：</strong><a href="/posts/f2b20d45.html">机器学习中评估分类器性能</a></li><li class="post-copyright-date"><strong>发布时间：</strong>2019年10月21日 - 17:33:21</li><li class="post-copyright-updated"><strong>更新时间：</strong>2021年02月03日 - 6:56:56</li><li class="post-copyright-license"><strong>版权声明：</strong>本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by-nc-sa/3.0/cn/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0 CN</a> 许可协议。转载请注明出处！</li></ul></div><br><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a class="article-share-link" data-url="https://wiki.hushhw.cn/posts/f2b20d45.html" data-id="ckkp2xupq00fsf8tlgtuj8ww5" data-qrcode="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAK4AAACuCAAAAACKZ2kyAAABxklEQVR42u3aQQ7CMAxEUe5/6bKthJLOjBM3SL8rVAp92VjOOJ+PfF23637n95nR8/N/W3zBhQu3zL2ml/4CfQHz/x89Axcu3H7u/PVzela25mVxeB8uXLjHc5XWR18wXLhw/51b2Zu8UMjgwoUbcfXylNGz4ggXLty3uHpKue/zlnwXLly4EfcyLz0MVYJU++1w4cJt4eoFxV2MG6boTRJcuHB3c5Vi5Aad2aZFKotw4cJt5yoRaj1M0cvfsCODCxduOzeLOJU7C6JVuHDhtnDdQLOSyGaDE6kvgwsXbgt3fmfejlQOb0nlDy5cuJu5WWHSl+SWwodCBhcu3Je4eiRaPxFhxytw4cJt57pQt+tw2yBjyAoXLtylXHf74Q5Z3QNbSjQDFy7cHq4bW6yiK8sYhiNw4cJt4bptTTZezTZLcOHCPYHrDlT0war7K3taCxcu3DK3XlbcMpcd24ILF24ntzJYVV6pj1SVQQtcuHA7uZXiVRmyhu0UXLhwG7luocmaFT2Ktb+GCxfuMVx3S5Md3oILF+753OxwRjbKfRilwIULdzNX2fxkx7DcwxYPZRQuXLgt3GzwmRUyN7Ut5btw4cJNuF9+/wEv/tdiYAAAAABJRU5ErkJggg==">分享</a><div class="tags"><a href="/tags/Machine-Learning/">Machine Learning</a></div><div class="post-nav"><a class="pre" href="/posts/5b0e059c.html">常见 APK 恶意行为的代码特征总结</a><a class="next" href="/posts/6adc5586.html">使用virtualenv创建隔离环境</a></div><div class="recommended_posts"><h2>相关文章：</h2><li><a href="https://wiki.hushhw.cn/posts/125bcd75.html" target="_blank">iOS 砸壳总结</a></li><li><a href="https://wiki.hushhw.cn/posts/5b0e059c.html" target="_blank">常见 APK 恶意行为的代码特征总结</a></li><li><a href="https://wiki.hushhw.cn/posts/6adc5586.html" target="_blank">使用virtualenv创建隔离环境</a></li><li><a href="https://wiki.hushhw.cn/posts/d30e9e5e.html" target="_blank">HTTPS协议 &amp; TLS协议</a></li></div><div id="vcomment"></div><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="//photo.hushhw.cn/Valine.min.js"></script><script>var notify = 'false' == true ? true : false;
var verify = 'false' == true ? true : false;
var GUEST_INFO = ['nick','mail','link'];
var guest_info = 'nick,mail,link'.split(',').filter(function(item){
  return GUEST_INFO.indexOf(item) > -1
});
guest_info = guest_info.length == 0 ? GUEST_INFO :guest_info;
window.valine = new Valine({
  el:'#vcomment',
  notify:notify,
  verify:verify,
  appId:'YVxvrCNxpTLOcs83UfKCUOaI-gzGzoHsz',
  appKey:'5eaXH2FJm2nxSBIQL4INFBbW',
  placeholder:'居然什么也不说，哼',
  avatar:'robohash',
  guest_info:guest_info,
  pageSize:'10'
})</script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.2/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.2/jquery.fancybox.min.css"></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar-toc"><div class="stoc-article" id="sidebar-stoc"><strong class="stoc-title"><i class="fa fa-blind"> Contents </i></strong><div class="toc-nav" id="stoc"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#混淆矩阵（Confusion-Matrix）"><span class="toc-number">1.</span> <span class="toc-text">混淆矩阵（Confusion Matrix）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#精准率和召回率"><span class="toc-number">2.</span> <span class="toc-text">精准率和召回率</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#F1-Score"><span class="toc-number">3.</span> <span class="toc-text">F1 Score</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Precision-recall-的平衡"><span class="toc-number">4.</span> <span class="toc-text">Precision-recall 的平衡</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Precision-Recall-曲线"><span class="toc-number">5.</span> <span class="toc-text">Precision-Recall 曲线</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ROC-曲线"><span class="toc-number">6.</span> <span class="toc-text">ROC 曲线</span></a></li></ol></div></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">© 2018 - 2021 | <span class="footicon"><i class="fa fa-meh-o"></i></span><a rel="nofollow" target="_blank" href="https://wiki.hushhw.cn">hushhw × Wiki</a> | <a rel="nofollow" target="_blank" href="http://www.miibeian.gov.cn/">鄂ICP备17007175号-1</a><br> 
Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo | </a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho | </a>Accelerated by <a rel="nofollow" target="_blank" href="https://www.upyun.com/index.html"><img class="upyunimg" src="https://photo.hushhw.cn/images/又拍云120180930001119303.png"></a><br> <script src="https://photo.hushhw.cn/busuanzi.pure.mini.js" async="async"></script><span id="busuanzi_container_site_uv"></span><i class="fa fa-user-md"></i><span> 访问人数<span id="busuanzi_value_site_uv"></span></span> | <span id="busuanzi_container_site_pv"> </span><span class="footicon"><i class="fa fa-eye"></i></span><span> 访问量<span id="busuanzi_value_site_pv"></span></span></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script><script type="text/javascript" src="/js/toc.js?v=0.0.0" async></script></div></body></html>